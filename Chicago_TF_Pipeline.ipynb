{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4c7cfd1-b4f0-4e77-b63d-d6c5603de36e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.10.1\n",
      "TFX version: 1.11.0\n",
      "KFP version: 1.8.22\n",
      "TFMA version: 0.42.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import tensorflow as tf\n",
    "print('TensorFlow version: {}'.format(tf.__version__))\n",
    "from tfx import v1 as tfx\n",
    "print('TFX version: {}'.format(tfx.__version__))\n",
    "import kfp\n",
    "print('KFP version: {}'.format(kfp.__version__))\n",
    "import tensorflow_model_analysis as tfma\n",
    "print('TFMA version: {}'.format(tfma.__version__))\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07728ae-8620-4d11-893b-8469c887e048",
   "metadata": {},
   "source": [
    "## TFX Pipeline - Loading preprocessed Bigquery CSV Data from Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "590bf8f4-8e07-4bb0-9e19-4a67962c981b",
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_CLOUD_PROJECT = 'aa-ai-specialisation'         \n",
    "GOOGLE_CLOUD_PROJECT_NUMBER = '653183562498'  \n",
    "GOOGLE_CLOUD_REGION = 'us-central1'          \n",
    "GCS_BUCKET_NAME = 'aa_chicago_taxi_trips'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f73f5529-130d-4df1-a8f3-52cd2656c49e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIPELINE_ROOT: gs://aa_chicago_taxi_trips/pipeline_root/chicago-vertex-training\n"
     ]
    }
   ],
   "source": [
    "PIPELINE_NAME = 'chicago-vertex-training'\n",
    "PIPELINE_ROOT = 'gs://{}/pipeline_root/{}'.format(GCS_BUCKET_NAME, PIPELINE_NAME)\n",
    "MODULE_ROOT = 'gs://{}/pipeline_module/{}'.format(GCS_BUCKET_NAME, PIPELINE_NAME)\n",
    "DATA_ROOT = 'gs://aa_chicago_taxi_trips/data/chicago_vertex_training'\n",
    "ENDPOINT_NAME = 'prediction-' + PIPELINE_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1f0c21d6-52e4-4c35-8258-26f967669ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_model_analysis as tfma\n",
    "\n",
    "\n",
    "def _create_pipeline(pipeline_name: str, pipeline_root: str, data_root: str,\n",
    "                     module_file: str, endpoint_name: str, project_id: str,\n",
    "                     region: str, use_gpu: bool) -> tfx.dsl.Pipeline:\n",
    "    output_config = proto.Output(\n",
    "             split_config=example_gen_pb2.SplitConfig(splits=[\n",
    "                 proto.SplitConfig.Split(name='train', hash_buckets=4),\n",
    "                 proto.SplitConfig.Split(name='eval', hash_buckets=1)\n",
    "             ]))\n",
    "    example_gen = tfx.components.CsvExampleGen(input_base=data_root, output_config=output_config)\n",
    "    vertex_job_spec = {\n",
    "      'project': project_id,\n",
    "      'worker_pool_specs': [{\n",
    "          'machine_spec': {\n",
    "              'machine_type': 'n1-standard-16',\n",
    "          },\n",
    "          'replica_count': 1,\n",
    "          'container_spec': {\n",
    "              'image_uri': 'gcr.io/tfx-oss-public/tfx:{}'.format(tfx.__version__),\n",
    "          },\n",
    "      }],\n",
    "    }\n",
    "    if use_gpu:\n",
    "        vertex_job_spec['worker_pool_specs'][0]['machine_spec'].update({\n",
    "            'accelerator_type': 'NVIDIA_TESLA_K80',\n",
    "            'accelerator_count': 2\n",
    "        })\n",
    "\n",
    "    trainer = tfx.extensions.google_cloud_ai_platform.Trainer(\n",
    "      module_file=module_file,\n",
    "      examples=example_gen.outputs['examples'],\n",
    "      train_args=tfx.proto.TrainArgs(num_steps=100),\n",
    "      eval_args=tfx.proto.EvalArgs(num_steps=5),\n",
    "      custom_config={\n",
    "          tfx.extensions.google_cloud_ai_platform.ENABLE_VERTEX_KEY:\n",
    "              True,\n",
    "          tfx.extensions.google_cloud_ai_platform.VERTEX_REGION_KEY:\n",
    "              region,\n",
    "          tfx.extensions.google_cloud_ai_platform.TRAINING_ARGS_KEY:\n",
    "              vertex_job_spec,\n",
    "          'use_gpu':\n",
    "              use_gpu,\n",
    "      })\n",
    "    \n",
    "    eval_config = tfma.EvalConfig(\n",
    "        model_specs=[\n",
    "            tfma.ModelSpec(label_key='fare')\n",
    "        ],\n",
    "        metrics_specs=[\n",
    "            tfma.MetricsSpec(\n",
    "               metrics=[\n",
    "                    tfma.MetricConfig(class_name='MeanSquaredError')\n",
    "                ]\n",
    "            )\n",
    "        ],\n",
    "        slicing_specs=[\n",
    "            tfma.SlicingSpec(),\n",
    "    ])\n",
    "    evaluator = tfx.components.Evaluator(\n",
    "        examples=example_gen.outputs['examples'],\n",
    "        model=trainer.outputs['model'],\n",
    "        eval_config=eval_config,\n",
    "    )\n",
    "\n",
    "    vertex_serving_spec = {\n",
    "      'project_id': project_id,\n",
    "      'endpoint_name': endpoint_name,\n",
    "      'machine_type': 'n1-standard-16',\n",
    "    }\n",
    "\n",
    "    serving_image = 'us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-6:latest'\n",
    "    if use_gpu:\n",
    "        vertex_serving_spec.update({\n",
    "            'accelerator_type': 'NVIDIA_TESLA_K80',\n",
    "            'accelerator_count': 2\n",
    "        })\n",
    "        serving_image = 'us-docker.pkg.dev/vertex-ai/prediction/tf2-gpu.2-6:latest'\n",
    "    pusher = tfx.extensions.google_cloud_ai_platform.Pusher(\n",
    "      model=trainer.outputs['model'],\n",
    "      custom_config={\n",
    "          tfx.extensions.google_cloud_ai_platform.ENABLE_VERTEX_KEY:\n",
    "              True,\n",
    "          tfx.extensions.google_cloud_ai_platform.VERTEX_REGION_KEY:\n",
    "              region,\n",
    "          tfx.extensions.google_cloud_ai_platform.VERTEX_CONTAINER_IMAGE_URI_KEY:\n",
    "              serving_image,\n",
    "          tfx.extensions.google_cloud_ai_platform.SERVING_ARGS_KEY:\n",
    "            vertex_serving_spec,\n",
    "      })\n",
    "\n",
    "    components = [\n",
    "      example_gen,\n",
    "      trainer,\n",
    "      evaluator,\n",
    "      pusher,\n",
    "    ]\n",
    "\n",
    "    return tfx.dsl.Pipeline(\n",
    "      pipeline_name=pipeline_name,\n",
    "      pipeline_root=pipeline_root,\n",
    "      components=components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3b876d16-4188-430d-a83e-1d128374d688",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Generating ephemeral wheel package for '/var/tmp/tmp3bjkq38m/Chicago_trainer_pipeline_vertex.py' (including modules: ['Chicago_trainer_pipeline_vertex']).\n",
      "INFO:absl:User module package has hash fingerprint version 86262b9e77e085256147a3092d50c6626335b07de8bcb1c4a9d15960aae65dc0.\n",
      "INFO:absl:Executing: ['/opt/conda/bin/python', '/var/tmp/tmp8jdvw3c_/_tfx_generated_setup.py', 'bdist_wheel', '--bdist-dir', '/var/tmp/tmp6mnllzl7', '--dist-dir', '/var/tmp/tmpw33ak0i6']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running bdist_wheel\n",
      "running build\n",
      "running build_py\n",
      "creating build\n",
      "creating build/lib\n",
      "copying Chicago_trainer_pipeline_vertex.py -> build/lib\n",
      "installing to /var/tmp/tmp6mnllzl7\n",
      "running install\n",
      "running install_lib\n",
      "copying build/lib/Chicago_trainer_pipeline_vertex.py -> /var/tmp/tmp6mnllzl7\n",
      "running install_egg_info\n",
      "running egg_info\n",
      "creating tfx_user_code_Trainer.egg-info\n",
      "writing tfx_user_code_Trainer.egg-info/PKG-INFO\n",
      "writing dependency_links to tfx_user_code_Trainer.egg-info/dependency_links.txt\n",
      "writing top-level names to tfx_user_code_Trainer.egg-info/top_level.txt\n",
      "writing manifest file 'tfx_user_code_Trainer.egg-info/SOURCES.txt'\n",
      "reading manifest file 'tfx_user_code_Trainer.egg-info/SOURCES.txt'\n",
      "writing manifest file 'tfx_user_code_Trainer.egg-info/SOURCES.txt'\n",
      "Copying tfx_user_code_Trainer.egg-info to /var/tmp/tmp6mnllzl7/tfx_user_code_Trainer-0.0+86262b9e77e085256147a3092d50c6626335b07de8bcb1c4a9d15960aae65dc0-py3.7.egg-info\n",
      "running install_scripts\n",
      "creating /var/tmp/tmp6mnllzl7/tfx_user_code_Trainer-0.0+86262b9e77e085256147a3092d50c6626335b07de8bcb1c4a9d15960aae65dc0.dist-info/WHEEL\n",
      "creating '/var/tmp/tmpw33ak0i6/tfx_user_code_Trainer-0.0+86262b9e77e085256147a3092d50c6626335b07de8bcb1c4a9d15960aae65dc0-py3-none-any.whl' and adding '/var/tmp/tmp6mnllzl7' to it\n",
      "adding 'Chicago_trainer_pipeline_vertex.py'\n",
      "adding 'tfx_user_code_Trainer-0.0+86262b9e77e085256147a3092d50c6626335b07de8bcb1c4a9d15960aae65dc0.dist-info/METADATA'\n",
      "adding 'tfx_user_code_Trainer-0.0+86262b9e77e085256147a3092d50c6626335b07de8bcb1c4a9d15960aae65dc0.dist-info/WHEEL'\n",
      "adding 'tfx_user_code_Trainer-0.0+86262b9e77e085256147a3092d50c6626335b07de8bcb1c4a9d15960aae65dc0.dist-info/top_level.txt'\n",
      "adding 'tfx_user_code_Trainer-0.0+86262b9e77e085256147a3092d50c6626335b07de8bcb1c4a9d15960aae65dc0.dist-info/RECORD'\n",
      "removing /var/tmp/tmp6mnllzl7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
      "!!\n",
      "\n",
      "        ********************************************************************************\n",
      "        Please avoid running ``setup.py`` directly.\n",
      "        Instead, use pypa/build, pypa/installer or other\n",
      "        standards-based tools.\n",
      "\n",
      "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
      "        ********************************************************************************\n",
      "\n",
      "!!\n",
      "  self.initialize_options()\n",
      "INFO:absl:Successfully built user code wheel distribution at 'gs://aa_chicago_taxi_trips/pipeline_root/chicago-vertex-training/_wheels/tfx_user_code_Trainer-0.0+86262b9e77e085256147a3092d50c6626335b07de8bcb1c4a9d15960aae65dc0-py3-none-any.whl'; target user module is 'Chicago_trainer_pipeline_vertex'.\n",
      "INFO:absl:Full user module path is 'Chicago_trainer_pipeline_vertex@gs://aa_chicago_taxi_trips/pipeline_root/chicago-vertex-training/_wheels/tfx_user_code_Trainer-0.0+86262b9e77e085256147a3092d50c6626335b07de8bcb1c4a9d15960aae65dc0-py3-none-any.whl'\n"
     ]
    }
   ],
   "source": [
    "PIPELINE_DEFINITION_FILE = PIPELINE_NAME + '_pipeline.json'\n",
    "ENDPOINT_NAME = 'prediction-' + PIPELINE_NAME\n",
    "runner = tfx.orchestration.experimental.KubeflowV2DagRunner(\n",
    "    config=tfx.orchestration.experimental.KubeflowV2DagRunnerConfig(),\n",
    "    output_filename=PIPELINE_DEFINITION_FILE)\n",
    "_ = runner.run(\n",
    "    _create_pipeline(\n",
    "        pipeline_name=PIPELINE_NAME,\n",
    "        pipeline_root=PIPELINE_ROOT,\n",
    "        data_root=DATA_ROOT,\n",
    "        module_file=os.path.join(MODULE_ROOT, _trainer_module_file),\n",
    "        endpoint_name=ENDPOINT_NAME,\n",
    "        project_id=GOOGLE_CLOUD_PROJECT,\n",
    "        region=GOOGLE_CLOUD_REGION,\n",
    "        # We will use CPUs only for now.\n",
    "        use_gpu=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "42abacf3-1d6a-46a0-93c6-86df63bcf0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.pipeline_jobs:Creating PipelineJob\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineJob created. Resource name: projects/653183562498/locations/us-central1/pipelineJobs/chicago-vertex-training-20240110101055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob created. Resource name: projects/653183562498/locations/us-central1/pipelineJobs/chicago-vertex-training-20240110101055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To use this PipelineJob in another session:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.pipeline_jobs:To use this PipelineJob in another session:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipeline_job = aiplatform.PipelineJob.get('projects/653183562498/locations/us-central1/pipelineJobs/chicago-vertex-training-20240110101055')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.pipeline_jobs:pipeline_job = aiplatform.PipelineJob.get('projects/653183562498/locations/us-central1/pipelineJobs/chicago-vertex-training-20240110101055')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/chicago-vertex-training-20240110101055?project=653183562498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.pipeline_jobs:View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/chicago-vertex-training-20240110101055?project=653183562498\n"
     ]
    }
   ],
   "source": [
    "# docs_infra: no_execute\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud.aiplatform import pipeline_jobs\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "aiplatform.init(project=GOOGLE_CLOUD_PROJECT, location=GOOGLE_CLOUD_REGION)\n",
    "\n",
    "job = pipeline_jobs.PipelineJob(template_path=PIPELINE_DEFINITION_FILE,\n",
    "                                display_name=PIPELINE_NAME)\n",
    "job.submit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c100e1-d401-4cf7-b723-83050671cd9f",
   "metadata": {},
   "source": [
    "## TFX E2E Pipeline - Loading Raw CSV Data from Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b113175f-e580-47e1-be3e-1e10d3057039",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_NAME = 'chicago-vertex-training'\n",
    "PIPELINE_ROOT = 'gs://{}/pipeline_root/{}'.format(GCS_BUCKET_NAME, PIPELINE_NAME)\n",
    "MODULE_ROOT = 'gs://{}/pipeline_module/{}'.format(GCS_BUCKET_NAME, PIPELINE_NAME)\n",
    "DATA_ROOT = 'gs://aa_chicago_taxi_trips/data/chicago_vertex_training/raw_data'\n",
    "ENDPOINT_NAME = 'prediction-' + PIPELINE_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2195e83-7949-4a4b-ba9b-a75849bdc35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_model_analysis as tfma\n",
    "from tfx.components import Transform\n",
    "from tfx.components import StatisticsGen, SchemaGen\n",
    "from tfx.extensions.google_cloud_big_query.example_gen.component import BigQueryExampleGen\n",
    "\n",
    "def _create_pipeline(pipeline_name: str, pipeline_root: str, data_root: str,\n",
    "                     module_root: str, endpoint_name: str, project_id: str,\n",
    "                     region: str, use_gpu: bool) -> tfx.dsl.Pipeline:\n",
    "\n",
    "    _trainer_module_file = \"Chicago_trainer_pipeline_vertex.py\"\n",
    "    _transform_module_file = \"preprocessing.py\"\n",
    "    output_config = proto.Output(\n",
    "             split_config=example_gen_pb2.SplitConfig(splits=[\n",
    "                 proto.SplitConfig.Split(name='train', hash_buckets=4),\n",
    "                 proto.SplitConfig.Split(name='eval', hash_buckets=1)\n",
    "             ]))\n",
    "    example_gen = tfx.components.CsvExampleGen(input_base=data_root, output_config=output_config)\n",
    "\n",
    "    vertex_job_spec = {\n",
    "      'project': project_id,\n",
    "      'worker_pool_specs': [{\n",
    "          'machine_spec': {\n",
    "              'machine_type': 'n1-standard-16',\n",
    "          },\n",
    "          'replica_count': 1,\n",
    "          'container_spec': {\n",
    "              'image_uri': 'gcr.io/tfx-oss-public/tfx:{}'.format(tfx.__version__),\n",
    "          },\n",
    "      }],\n",
    "    }\n",
    "    if use_gpu:\n",
    "\n",
    "        vertex_job_spec['worker_pool_specs'][0]['machine_spec'].update({\n",
    "            'accelerator_type': 'NVIDIA_TESLA_K80',\n",
    "            'accelerator_count': 2\n",
    "        })\n",
    "    statistics_gen = StatisticsGen(examples=example_gen.outputs['examples'])\n",
    "\n",
    "    schema_gen = SchemaGen(statistics=statistics_gen.outputs['statistics'])\n",
    "\n",
    "    transform = Transform(\n",
    "        examples=example_gen.outputs['examples'],\n",
    "        schema=schema_gen.outputs['schema'],\n",
    "        module_file=os.path.join(module_root, _transform_module_file)\n",
    "    )\n",
    "    trainer = tfx.extensions.google_cloud_ai_platform.Trainer(\n",
    "        module_file=os.path.join(module_root, _trainer_module_file),\n",
    "        examples=transform.outputs['transformed_examples'],  \n",
    "        transform_graph=transform.outputs['transform_graph'],  \n",
    "        schema=schema_gen.outputs['schema'],\n",
    "        train_args=tfx.proto.TrainArgs(num_steps=100),\n",
    "        eval_args=tfx.proto.EvalArgs(num_steps=5),\n",
    "        custom_config={\n",
    "          tfx.extensions.google_cloud_ai_platform.ENABLE_VERTEX_KEY:\n",
    "              True,\n",
    "          tfx.extensions.google_cloud_ai_platform.VERTEX_REGION_KEY:\n",
    "              region,\n",
    "          tfx.extensions.google_cloud_ai_platform.TRAINING_ARGS_KEY:\n",
    "              vertex_job_spec,\n",
    "          'use_gpu':\n",
    "              use_gpu,\n",
    "        })\n",
    "    \n",
    "    eval_config = tfma.EvalConfig(\n",
    "        model_specs=[\n",
    "            tfma.ModelSpec(label_key='fare')\n",
    "        ],\n",
    "        metrics_specs=[\n",
    "            tfma.MetricsSpec(\n",
    "               metrics=[\n",
    "                    tfma.MetricConfig(class_name='MeanSquaredError')\n",
    "                ]\n",
    "            )\n",
    "        ],\n",
    "        slicing_specs=[\n",
    "            tfma.SlicingSpec(),\n",
    "            tfma.SlicingSpec(feature_keys=['trip_start_hour'])\n",
    "    ])\n",
    "    evaluator = tfx.components.Evaluator(\n",
    "        examples=transform.outputs['transformed_examples'],  \n",
    "        model=trainer.outputs['model'],\n",
    "        eval_config=eval_config,\n",
    "    )\n",
    "\n",
    "    vertex_serving_spec = {\n",
    "      'project_id': project_id,\n",
    "      'endpoint_name': endpoint_name,\n",
    "      'machine_type': 'n1-standard-16',\n",
    "    }\n",
    "\n",
    "    serving_image = 'us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-6:latest'\n",
    "    if use_gpu:\n",
    "        vertex_serving_spec.update({\n",
    "            'accelerator_type': 'NVIDIA_TESLA_K80',\n",
    "            'accelerator_count': 2\n",
    "        })\n",
    "        serving_image = 'us-docker.pkg.dev/vertex-ai/prediction/tf2-gpu.2-6:latest'\n",
    "\n",
    "    pusher = tfx.extensions.google_cloud_ai_platform.Pusher(\n",
    "      model=trainer.outputs['model'],\n",
    "      custom_config={\n",
    "          tfx.extensions.google_cloud_ai_platform.ENABLE_VERTEX_KEY:\n",
    "              True,\n",
    "          tfx.extensions.google_cloud_ai_platform.VERTEX_REGION_KEY:\n",
    "              region,\n",
    "          tfx.extensions.google_cloud_ai_platform.VERTEX_CONTAINER_IMAGE_URI_KEY:\n",
    "              serving_image,\n",
    "          tfx.extensions.google_cloud_ai_platform.SERVING_ARGS_KEY:\n",
    "            vertex_serving_spec,\n",
    "      })\n",
    "\n",
    "    components = [\n",
    "        example_gen,\n",
    "        statistics_gen,\n",
    "        schema_gen,\n",
    "        transform, \n",
    "        trainer,\n",
    "        evaluator,\n",
    "        pusher,\n",
    "    ]\n",
    "\n",
    "    return tfx.dsl.Pipeline(\n",
    "      pipeline_name=pipeline_name,\n",
    "      pipeline_root=pipeline_root,\n",
    "      components=components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ced434a6-24fb-441b-90b7-fcd47d9a27ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running bdist_wheel\n",
      "running build\n",
      "running build_py\n",
      "creating build\n",
      "creating build/lib\n",
      "copying preprocessing.py -> build/lib\n",
      "installing to /var/tmp/tmpd_mdvl31\n",
      "running install\n",
      "running install_lib\n",
      "copying build/lib/preprocessing.py -> /var/tmp/tmpd_mdvl31\n",
      "running install_egg_info\n",
      "running egg_info\n",
      "creating tfx_user_code_Transform.egg-info\n",
      "writing tfx_user_code_Transform.egg-info/PKG-INFO\n",
      "writing dependency_links to tfx_user_code_Transform.egg-info/dependency_links.txt\n",
      "writing top-level names to tfx_user_code_Transform.egg-info/top_level.txt\n",
      "writing manifest file 'tfx_user_code_Transform.egg-info/SOURCES.txt'\n",
      "reading manifest file 'tfx_user_code_Transform.egg-info/SOURCES.txt'\n",
      "writing manifest file 'tfx_user_code_Transform.egg-info/SOURCES.txt'\n",
      "Copying tfx_user_code_Transform.egg-info to /var/tmp/tmpd_mdvl31/tfx_user_code_Transform-0.0+aecb5162972a13bf42e8d7a1f96001c6ca3d5f286f7913fba122584b5660f8a9-py3.7.egg-info\n",
      "running install_scripts\n",
      "creating /var/tmp/tmpd_mdvl31/tfx_user_code_Transform-0.0+aecb5162972a13bf42e8d7a1f96001c6ca3d5f286f7913fba122584b5660f8a9.dist-info/WHEEL\n",
      "creating '/var/tmp/tmpjpjb30wg/tfx_user_code_Transform-0.0+aecb5162972a13bf42e8d7a1f96001c6ca3d5f286f7913fba122584b5660f8a9-py3-none-any.whl' and adding '/var/tmp/tmpd_mdvl31' to it\n",
      "adding 'preprocessing.py'\n",
      "adding 'tfx_user_code_Transform-0.0+aecb5162972a13bf42e8d7a1f96001c6ca3d5f286f7913fba122584b5660f8a9.dist-info/METADATA'\n",
      "adding 'tfx_user_code_Transform-0.0+aecb5162972a13bf42e8d7a1f96001c6ca3d5f286f7913fba122584b5660f8a9.dist-info/WHEEL'\n",
      "adding 'tfx_user_code_Transform-0.0+aecb5162972a13bf42e8d7a1f96001c6ca3d5f286f7913fba122584b5660f8a9.dist-info/top_level.txt'\n",
      "adding 'tfx_user_code_Transform-0.0+aecb5162972a13bf42e8d7a1f96001c6ca3d5f286f7913fba122584b5660f8a9.dist-info/RECORD'\n",
      "removing /var/tmp/tmpd_mdvl31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
      "!!\n",
      "\n",
      "        ********************************************************************************\n",
      "        Please avoid running ``setup.py`` directly.\n",
      "        Instead, use pypa/build, pypa/installer or other\n",
      "        standards-based tools.\n",
      "\n",
      "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
      "        ********************************************************************************\n",
      "\n",
      "!!\n",
      "  self.initialize_options()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running bdist_wheel\n",
      "running build\n",
      "running build_py\n",
      "creating build\n",
      "creating build/lib\n",
      "copying Chicago_trainer_pipeline_vertex.py -> build/lib\n",
      "installing to /var/tmp/tmpb4dz5bng\n",
      "running install\n",
      "running install_lib\n",
      "copying build/lib/Chicago_trainer_pipeline_vertex.py -> /var/tmp/tmpb4dz5bng\n",
      "running install_egg_info\n",
      "running egg_info\n",
      "creating tfx_user_code_Trainer.egg-info\n",
      "writing tfx_user_code_Trainer.egg-info/PKG-INFO\n",
      "writing dependency_links to tfx_user_code_Trainer.egg-info/dependency_links.txt\n",
      "writing top-level names to tfx_user_code_Trainer.egg-info/top_level.txt\n",
      "writing manifest file 'tfx_user_code_Trainer.egg-info/SOURCES.txt'\n",
      "reading manifest file 'tfx_user_code_Trainer.egg-info/SOURCES.txt'\n",
      "writing manifest file 'tfx_user_code_Trainer.egg-info/SOURCES.txt'\n",
      "Copying tfx_user_code_Trainer.egg-info to /var/tmp/tmpb4dz5bng/tfx_user_code_Trainer-0.0+86262b9e77e085256147a3092d50c6626335b07de8bcb1c4a9d15960aae65dc0-py3.7.egg-info\n",
      "running install_scripts\n",
      "creating /var/tmp/tmpb4dz5bng/tfx_user_code_Trainer-0.0+86262b9e77e085256147a3092d50c6626335b07de8bcb1c4a9d15960aae65dc0.dist-info/WHEEL\n",
      "creating '/var/tmp/tmpee_5e6l1/tfx_user_code_Trainer-0.0+86262b9e77e085256147a3092d50c6626335b07de8bcb1c4a9d15960aae65dc0-py3-none-any.whl' and adding '/var/tmp/tmpb4dz5bng' to it\n",
      "adding 'Chicago_trainer_pipeline_vertex.py'\n",
      "adding 'tfx_user_code_Trainer-0.0+86262b9e77e085256147a3092d50c6626335b07de8bcb1c4a9d15960aae65dc0.dist-info/METADATA'\n",
      "adding 'tfx_user_code_Trainer-0.0+86262b9e77e085256147a3092d50c6626335b07de8bcb1c4a9d15960aae65dc0.dist-info/WHEEL'\n",
      "adding 'tfx_user_code_Trainer-0.0+86262b9e77e085256147a3092d50c6626335b07de8bcb1c4a9d15960aae65dc0.dist-info/top_level.txt'\n",
      "adding 'tfx_user_code_Trainer-0.0+86262b9e77e085256147a3092d50c6626335b07de8bcb1c4a9d15960aae65dc0.dist-info/RECORD'\n",
      "removing /var/tmp/tmpb4dz5bng\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
      "!!\n",
      "\n",
      "        ********************************************************************************\n",
      "        Please avoid running ``setup.py`` directly.\n",
      "        Instead, use pypa/build, pypa/installer or other\n",
      "        standards-based tools.\n",
      "\n",
      "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
      "        ********************************************************************************\n",
      "\n",
      "!!\n",
      "  self.initialize_options()\n"
     ]
    }
   ],
   "source": [
    "PIPELINE_DEFINITION_FILE = PIPELINE_NAME + '_pipeline.json'\n",
    "ENDPOINT_NAME = 'prediction-' + PIPELINE_NAME\n",
    "runner = tfx.orchestration.experimental.KubeflowV2DagRunner(\n",
    "    config=tfx.orchestration.experimental.KubeflowV2DagRunnerConfig(),\n",
    "    output_filename=PIPELINE_DEFINITION_FILE)\n",
    "_ = runner.run(\n",
    "    _create_pipeline(\n",
    "        pipeline_name=PIPELINE_NAME,\n",
    "        pipeline_root=PIPELINE_ROOT,\n",
    "        data_root=DATA_ROOT,\n",
    "        module_root=MODULE_ROOT,\n",
    "        endpoint_name=ENDPOINT_NAME,\n",
    "        project_id=GOOGLE_CLOUD_PROJECT,\n",
    "        region=GOOGLE_CLOUD_REGION,\n",
    "        # We will use CPUs only for now.\n",
    "        use_gpu=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3181106d-af4d-41ed-a9d4-a497cdc6bc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# docs_infra: no_execute\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud.aiplatform import pipeline_jobs\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "aiplatform.init(project=GOOGLE_CLOUD_PROJECT, location=GOOGLE_CLOUD_REGION)\n",
    "\n",
    "job = pipeline_jobs.PipelineJob(template_path=PIPELINE_DEFINITION_FILE,\n",
    "                                display_name=PIPELINE_NAME)\n",
    "job.submit()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m111",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m111"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
